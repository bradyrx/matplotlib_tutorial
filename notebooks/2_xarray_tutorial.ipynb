{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `xarray` Processing with `matplotlib`\n",
    "\n",
    "---\n",
    "\n",
    "Author: Riley X. Brady\n",
    "\n",
    "Date: October 22nd, 2019\n",
    "\n",
    "Contact: \n",
    "* riley.brady@colorado.edu\n",
    "* www.rileyxbrady.com\n",
    "\n",
    "---\n",
    "\n",
    "`xarray` extends all of the functionality of `numpy` to *labeled* arrays. Since climate data is highly dimensional (e.g. time, lat, lon, depth), this is extremely useful and makes for analyzing climate data much easier!\n",
    "\n",
    "## References\n",
    "\n",
    "1. [xarray documentation](http://xarray.pydata.org/en/stable/) - Their documentation is some of the best out there for a python package. It's worth reading through some of these pages!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-22T18:11:40.171533Z",
     "start_time": "2019-10-22T18:11:39.617450Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import xarray as xr\n",
    "\n",
    "# This is generally bad practice. But 'numpy' spits out a lot of warnings since\n",
    "# we have NaNs on our grid due to coastlines/land. This just makes sure\n",
    "# they don't get printed out every time.\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Loading in Our Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we will work with the ERSSTv4 dataset from NOAA ([link](https://www.ncdc.noaa.gov/data-access/marineocean-data/extended-reconstructed-sea-surface-temperature-ersst-v4)). The original data span 1850-2019, but I subset it to 1920-2018 for Github storage reasons. The data is interpolated to a 2deg x 2deg regular lat/lon grid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-22T18:11:40.197561Z",
     "start_time": "2019-10-22T18:11:40.172786Z"
    }
   },
   "outputs": [],
   "source": [
    "# xarray does a great job with netCDF data, which is a classic data type\n",
    "# for climate science.\n",
    "ds = xr.open_dataset('../data/sst.mnmean.v4.1920-2018.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "netCDF is an appealing data format since it does a great job at storing metadata (descriptions of your data).\n",
    "\n",
    "**Dimensions**: We have core dimensions `lat`, `lon`, and `time`.\n",
    "\n",
    "**Variables**: We have variables that can be assigned only to these dimensions.\n",
    "\n",
    "* `lat`: is the coordinate variable that describes the `lat` dimension. You see it is just of `lat` dimensionality and actually contains degrees from 90S to 90N.\n",
    "* `lon`: is the coordinate variable that describes the `lon` dimension. Similarly it runs from 0 to 360 degrees E.\n",
    "* `sst`: is our main data variable of dimensions ('time', 'lat', 'lon').\n",
    "* `time`: describes our time dimension with actual dates from January 1920 to December 2018."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-22T18:11:40.202745Z",
     "start_time": "2019-10-22T18:11:40.199179Z"
    }
   },
   "outputs": [],
   "source": [
    "print(ds.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Simple Manipulation of our Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From here on out, we're just working with the SST variable from our dataset, so we'll extract that. `xarray` Datasets can hold multiple variables (e.g., sea surface temperature, salinity, chlorophyll) if you want to do the same operations to a lot of variables at once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-22T18:11:40.211424Z",
     "start_time": "2019-10-22T18:11:40.204937Z"
    }
   },
   "outputs": [],
   "source": [
    "ds = ds['sst']\n",
    "print(ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`xarray` makes it easy to do operations over specific dimensions. For instance, we can take the mean across all time without worrying what dimension number time is.\n",
    "\n",
    "(The equivalent `numpy` operation here would be `np.nanmean(ds, axis=0)` which requires us to remember/keep track of which axis the time dimension is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-22T18:11:40.737798Z",
     "start_time": "2019-10-22T18:11:40.213039Z"
    }
   },
   "outputs": [],
   "source": [
    "time_mean = ds.mean('time')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`xarray` features a really robust plotting package. That won't be the focus of this notebook, but you can look at all the awesome features here: http://xarray.pydata.org/en/stable/plotting.html\n",
    "\n",
    "You'll notice that it's really just pulling functionality from `matplotlib` without you having to worry about it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-22T18:11:40.960322Z",
     "start_time": "2019-10-22T18:11:40.738859Z"
    }
   },
   "outputs": [],
   "source": [
    "time_mean.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because we have our time axis described from dates, we can very easily take a mean over a specific slice of time. This is a **headache** in languages like `MATLAB` or just using `numpy`. You have to know exactly what indices your time frame spans, and have to account for whether the language is 0-based indexing or 1-based indexing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-22T18:11:40.970335Z",
     "start_time": "2019-10-22T18:11:40.961601Z"
    }
   },
   "outputs": [],
   "source": [
    "# We use the .sel() operator which can select over some portion of your index.\n",
    "# First let's prove that it's the correct time slice.\n",
    "print(ds.sel(time=slice('1970', '2000')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-22T18:11:41.305457Z",
     "start_time": "2019-10-22T18:11:40.972535Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Now we can take the mean over that slice.\n",
    "time_mean = ds.sel(time=slice('1970', '2000')).mean('time')\n",
    "\n",
    "# We can use what we learned about matplotlib here as well.\n",
    "f, ax = plt.subplots()\n",
    "time_mean.plot(ax=ax, cmap='viridis', vmin=-2, vmax=30)\n",
    "\n",
    "ax.set_title('1970-2000 SST Climatology')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong><span style=\"color:red\">Try taking means over different time slices and plotting them.</span></strong> You can also designate the month to start/end your slice on, e.g.:\n",
    "\n",
    "`ds.sel(time=slice('1993-12', '1995-01'))` \n",
    "\n",
    "will slice from Dec. 1993 to January 1995."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can leverage this to look at the change in Sea Surface Temperatures over this observed period. Let's take a 1999-2018 average (20 years) and subtract the 1920-1939 average from it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-22T18:11:41.347853Z",
     "start_time": "2019-10-22T18:11:41.306897Z"
    }
   },
   "outputs": [],
   "source": [
    "# Take 20-year slices in the same way as before\n",
    "later_period = ds.sel(time=slice('1999', '2018')).mean('time')\n",
    "earlier_period = ds.sel(time=slice('1920', '1939')).mean('time')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we just subtract those two to get a change over time. This is similar to a linear trend, but instead we are just taking climatologies at either end of the time series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-22T18:11:41.354543Z",
     "start_time": "2019-10-22T18:11:41.349771Z"
    }
   },
   "outputs": [],
   "source": [
    "delta_sst = later_period - earlier_period"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can plot it! Here I use some features from the `xarray` plotting package that are outlined in the [documentation](http://xarray.pydata.org/en/stable/plotting.html).\n",
    "\n",
    "You can see the \"warming hole\" off Greenland due to freshwater discharge from glacial melt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-22T18:11:42.437636Z",
     "start_time": "2019-10-22T18:11:41.356113Z"
    }
   },
   "outputs": [],
   "source": [
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "\n",
    "f, ax = plt.subplots(figsize=(8,6),\n",
    "                     subplot_kw=dict(projection=ccrs.Robinson(central_longitude=180)))\n",
    "\n",
    "delta_sst.plot(# Make sure you assign the geo-axis here.\n",
    "                ax=ax, \n",
    "                # We're going to a funky projection, so need to\n",
    "                # transform\n",
    "                transform=ccrs.PlateCarree(),\n",
    "                # Set the colormap bounds\n",
    "                vmin=-2, vmax=2, cmap='RdBu_r',\n",
    "                cbar_kwargs={'orientation': 'horizontal',\n",
    "                            'label': '$\\Delta$SST'})\n",
    "\n",
    "ax.add_feature(cfeature.LAND, color='k', zorder=4)\n",
    "ax.set_title('Change in Sea Surface Temperature\\n [1999-2018 minus 1920-1939]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong><span style=\"color:red\">Try plotting the difference over your own time slice. Or perhaps mess with the colormap and map projection.</span></strong> You also don't need to *slice* over time. You could select a single time and plot that (e.g., your birthday month):\n",
    "\n",
    "`ds.sel(time='1993-12)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Climatologies\n",
    "\n",
    "Climatologies are classic in the climate sciences. Above we just looked at climatological conditions over a set of years, e.g., a 30 year span. What about a monthly climatology? What does January *usually* look like over this time period?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-22T18:11:42.443288Z",
     "start_time": "2019-10-22T18:11:42.438551Z"
    }
   },
   "outputs": [],
   "source": [
    "# Let's first slice to a modern period, so that the long-term warming trend doesn't \n",
    "# influence our results too much.\n",
    "modern_slice = ds.sel(time=slice('1995', '2015'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`xarray` leverages `pandas` to have an amazingly simple command to get our climatology. We just simply group our data by a certain standard (`.groupby()`) and then apply a simple function over it (in our case, the mean).\n",
    "\n",
    "In return, we get a Dataset with a new dimension called `month`. This holds our January average SST, February, and so on over 1995 to 2005."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-22T18:11:42.485828Z",
     "start_time": "2019-10-22T18:11:42.444751Z"
    }
   },
   "outputs": [],
   "source": [
    "# It's this easy!\n",
    "monthly_clim = modern_slice.groupby('time.month').mean('time')\n",
    "\n",
    "print(monthly_clim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Under the hood, it's actually finding every time index that meets the standards of a certain month. So here it's saying the Januarys should be the mean over index 0, 12, 24, ... and so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-22T18:11:42.491489Z",
     "start_time": "2019-10-22T18:11:42.487184Z"
    }
   },
   "outputs": [],
   "source": [
    "print(modern_slice.groupby('time.month').groups)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can plot our monthly climatology very easy!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-22T18:11:44.659562Z",
     "start_time": "2019-10-22T18:11:42.492853Z"
    }
   },
   "outputs": [],
   "source": [
    "# Here I use `col='month'` to say that I want each individual plot to be a month\n",
    "# and col_wrap so that it doesn't just put 12 in a line.\n",
    "monthly_clim.plot(col='month', col_wrap=4, vmin=-2, vmax=30,\n",
    "                  cmap='inferno')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's hard to see the differences here, so we could just subtract out the mean over that slice to show the seasonal cycle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-22T18:11:44.677491Z",
     "start_time": "2019-10-22T18:11:44.660644Z"
    }
   },
   "outputs": [],
   "source": [
    "seasonal_cycle_anomalies = monthly_clim - modern_slice.mean('time')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can see the progression of the seasonal cycle!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-22T18:11:46.839647Z",
     "start_time": "2019-10-22T18:11:44.678729Z"
    }
   },
   "outputs": [],
   "source": [
    "seasonal_cycle_anomalies.plot(col='month', col_wrap=4, robust=True,\n",
    "                              cmap='BrBG_r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong><span style=\"color:red\">Explore here!</span></strong> Try out `.groupby('time.year')` and see what happens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Practical Example: Nino3.4 Index\n",
    "\n",
    "Let's use what we've learned to compute the Nino3.4 index for this dataset. This index gives us a measure of the state of El Niño Southern Oscillation (ENSO). If it's in a positive state, we have an El Niño; if negative, it's a La Niña.\n",
    "\n",
    "Here's the instructions for computing the index: https://climatedataguide.ucar.edu/climate-data/nino-sst-indices-nino-12-3-34-4-oni-and-tni\n",
    "\n",
    "For the Nino3.4 index in particular:\n",
    "```\n",
    "Niño 3.4 (5N-5S, 170W-120W):  The  Niño 3.4 anomalies may be thought of as representing the average equatorial SSTs across the Pacific from about the dateline to the South American coast.  The Niño 3.4 index typically uses a 5-month running mean, and El Niño or La  Niña events are defined when the  Niño 3.4 SSTs exceed +/- 0.4C for a period of six months or more.\n",
    "```"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Our first step is to find the Nino3.4 box, which spans 5N to 5S and 170W to 120W."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-22T18:11:46.845283Z",
     "start_time": "2019-10-22T18:11:46.840716Z"
    }
   },
   "outputs": [],
   "source": [
    "# Note that the longitude spans 0 to 360, starting at the Prime Meridian.\n",
    "lon1 = -170 + 360\n",
    "lon2 = -120 + 360\n",
    "\n",
    "# We can use our same knowledge of indexing here!\n",
    "nino34_box = ds.sel(lat=slice(5, -5), lon=slice(lon1, lon2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like we selected the right box!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-22T18:11:46.851451Z",
     "start_time": "2019-10-22T18:11:46.847133Z"
    }
   },
   "outputs": [],
   "source": [
    "# Correct for 0 to 360 lon\n",
    "print(nino34_box.lon - 360)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-22T18:11:46.857268Z",
     "start_time": "2019-10-22T18:11:46.852890Z"
    }
   },
   "outputs": [],
   "source": [
    "print(nino34_box.lat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to take the mean over this box. We know how to do that! `xarray` can take a list of dimensions to perform the operation over to make things easier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-22T18:11:47.035458Z",
     "start_time": "2019-10-22T18:11:46.858762Z"
    }
   },
   "outputs": [],
   "source": [
    "nino34_averaged = nino34_box.mean(['lat', 'lon'])\n",
    "nino34_averaged.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The instructions say to take a 5-month running mean. This is to get over the fact that the raw data (above) are pretty noisy.\n",
    "\n",
    "Fortunately, `xarray` has a `rolling` function to take what they call a \"rolling\" mean: http://xarray.pydata.org/en/stable/generated/xarray.Dataset.rolling.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-22T18:11:47.045544Z",
     "start_time": "2019-10-22T18:11:47.037191Z"
    }
   },
   "outputs": [],
   "source": [
    "# Take a rolling mean over 5-months.\n",
    "nino34_smoothed = nino34_averaged.rolling(time=5).mean()\n",
    "\n",
    "print(nino34_smoothed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By taking a running mean, we average over 5 months, so we lose the first 4 time steps to NaNs. Let's get rid of those."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-22T18:11:47.051959Z",
     "start_time": "2019-10-22T18:11:47.048399Z"
    }
   },
   "outputs": [],
   "source": [
    "nino34_smoothed = nino34_smoothed.dropna('time')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's what this just did. It smooths by a bit, but not a ton since it's only 5 months."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-22T18:11:47.190686Z",
     "start_time": "2019-10-22T18:11:47.054559Z"
    }
   },
   "outputs": [],
   "source": [
    "# The original, noisy SST averages.\n",
    "nino34_averaged.plot(color='gray')\n",
    "# The smoothed version.\n",
    "nino34_smoothed.plot(color='r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly we should detrend our time series so that we remove the climate change signal *and* can look at anomalies to meet their criteria of exceeding +/- 0.4C. Unfortunately, `xarray` doesn't have a `detrend` function, so we'll just leverage `scipy` here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-22T18:11:47.340913Z",
     "start_time": "2019-10-22T18:11:47.192038Z"
    }
   },
   "outputs": [],
   "source": [
    "from scipy.signal import detrend\n",
    "NINO34 = detrend(nino34_smoothed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-22T18:11:47.344505Z",
     "start_time": "2019-10-22T18:11:47.342018Z"
    }
   },
   "outputs": [],
   "source": [
    "# The above operation returned a numpy object. So we're just going to\n",
    "# recreate it as an xarray object to get all of the plotting functionality back.\n",
    "ds = xr.DataArray(NINO34, dims='time', coords=[nino34_smoothed.time])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-22T18:11:47.477327Z",
     "start_time": "2019-10-22T18:11:47.345664Z"
    }
   },
   "outputs": [],
   "source": [
    "# Our Nino3.4 index!\n",
    "ds.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a bit more advanced, but let's use `xarray` to make a nice colored plot highligthing El Niño and La Niña events. To classify actual events, you'd actually need to find where e.g. the index is above 0.4C for 6 months straight to be an El Niño. Here we just color by red and blue if it's positive or negative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-22T18:11:47.623136Z",
     "start_time": "2019-10-22T18:11:47.478564Z"
    }
   },
   "outputs": [],
   "source": [
    "f, ax = plt.subplots()\n",
    "\n",
    "# Isolate positive and negative months based on these simple conditions\n",
    "el_nino = ds.where(ds > 0)\n",
    "la_nina = ds.where(ds < 0)\n",
    "                  \n",
    "ax.fill_between(el_nino['time'].values, el_nino.values, color='r')\n",
    "ax.fill_between(la_nina['time'].values, la_nina.values, color='b')\n",
    "\n",
    "ax.set_ylabel('Nino3.4 Index')\n",
    "ax.set_title('ENSO Index over 1920-2018 in ERSSTv4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong><span style=\"color:red\">If you're feeling inspired, try creating an index following one of the other ENSO conventions (e.g. Nino4 or Nino1+2).</span></strong> Does it look much different?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
